# Topic of Training

## CNN

- LOSS NAN : 将图片标准化；增加BN层； 减小BATCH； 使用HE等初始化可以解决

- 多个BATCH后LOSS 几乎没有变化（按优先级）

    - 减小LR 0.025 0.01 0.001 0.0001 ...

    - 改变初始化：有时随机初始化等不同的初始化方案会有意想不到的变化。好的初始化可以加快模型收敛

    - 注意优化最后FEATURE MAP的输出至少应该满足`1 X 1 X num_classes`

    - 使用`SGD` `RMSprop`等优化器，`ADAM`有时候可能难以训练

    - 减小BATCH，16、32、64 等小BATCH非常适合CNN训练，但有些环境不适用

    - 减少输出：实际训练中发现多个输出配置多个LOSS会是模型收敛非常缓慢。所有在设计模型的时候应该尽量只使用最少输出，或者将模型拆分成几部分，收敛后再将模型合并，导入权值

    - LOSS函数：在多个输出的情况下，每个输出分别使用一个LOSS也导致了模型收敛很慢。`设计只使用一个LOSS（待验证，因为改变LOSS可能还要改变label的格式）`

## 笔记

https://github.com/cs231n/cs231n.github.io

https://www.zybuluo.com/hanxiaoyang/note/442863

- 用一部分的数据测试你梯度计算是否正确，注意提到的注意点。
- 检查你的初始权重是否合理，在关掉正则化项的系统里，是否可以取得100%的准确度。
- 在训练过程中，对损失函数结果做记录，以及训练集和交叉验证集上的准确度。
- 最常见的权重更新方式是SGD+Momentum，推荐试试RMSProp自适应学习率更新算法。
- 随着时间推进要用不同的方式去衰减学习率。
- 用交叉验证等去搜索和找到最合适的超参数。
- 记得也做做模型融合的工作，对结果有帮助。

